{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('heart_disease_uci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_features\n",
      "['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "\n",
      "numerical_features\n",
      "['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is a DataFrame or a structure like that\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "if 'id' in numerical_features:\n",
    "    numerical_features.remove('id')\n",
    "    numerical_features.remove('num')\n",
    "    \n",
    "print(\"categorical_features\")\n",
    "print(categorical_features)\n",
    "print(\"\\nnumerical_features\")\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([460.5       ,  53.51086957, 132.13240418, 199.13033708,\n",
       "       137.54566474,   0.87878788,   0.6763754 ,   0.99565217])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing missing values with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer=SimpleImputer(strategy='mean')\n",
    "\n",
    "num_data=data.drop(categorical_features,axis=1)\n",
    "imputer.fit(num_data)\n",
    "imputer.statistics_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, 0 to 903\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        372 non-null    float64\n",
      " 1   age       372 non-null    float64\n",
      " 2   trestbps  372 non-null    float64\n",
      " 3   chol      372 non-null    float64\n",
      " 4   thalch    372 non-null    float64\n",
      " 5   oldpeak   372 non-null    float64\n",
      " 6   ca        372 non-null    float64\n",
      " 7   num       372 non-null    float64\n",
      " 8   sex       372 non-null    object \n",
      " 9   dataset   372 non-null    object \n",
      " 10  cp        372 non-null    object \n",
      " 11  fbs       372 non-null    object \n",
      " 12  restecg   372 non-null    object \n",
      " 13  exang     372 non-null    object \n",
      " 14  slope     372 non-null    object \n",
      " 15  thal      372 non-null    object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# handling the missing values\n",
    "data_imputed=imputer.transform(num_data)\n",
    "\n",
    "imputed_df=pd.DataFrame(data_imputed,columns=num_data.columns)\n",
    "data_1=pd.concat([imputed_df,data[categorical_features]],axis=1)\n",
    "\n",
    "data_1.dropna(subset=categorical_features,inplace=True)  #inplace is used to ensure that new dataset is not created it just alter the original dataset\n",
    "data_1.info()\n",
    "\n",
    "# to check if rows are removed when categories value(s) are missing\n",
    "# missing_categorical = data[categorical_features].isnull().sum()\n",
    "\n",
    "# # Print or view the count of missing values in categorical columns\n",
    "# print(missing_categorical)\n",
    "\n",
    "\n",
    "# target = data_1.iloc[:, 7]  # Assuming the target column is at index 7\n",
    "\n",
    "# # Remove the target column from the DataFrame to keep only features\n",
    "# data_1 = data_1.drop(columns=data_1.columns[7])\n",
    "\n",
    "\n",
    "# to ensure that the target and data have the same number of rows as some rows where removed in because of category\n",
    "# len(data_1)\n",
    "# len(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>exang</th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.719280</td>\n",
       "      <td>0.185953</td>\n",
       "      <td>0.247221</td>\n",
       "      <td>1.151950</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>False</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>fixed defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.355613</td>\n",
       "      <td>1.558087</td>\n",
       "      <td>0.730148</td>\n",
       "      <td>-1.364202</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>2.773361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>True</td>\n",
       "      <td>flat</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.355613</td>\n",
       "      <td>-0.678732</td>\n",
       "      <td>0.144881</td>\n",
       "      <td>-0.558491</td>\n",
       "      <td>1.420899</td>\n",
       "      <td>1.581516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>True</td>\n",
       "      <td>flat</td>\n",
       "      <td>reversable defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.970826</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>0.360506</td>\n",
       "      <td>1.666808</td>\n",
       "      <td>2.227746</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.527300</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>-0.111815</td>\n",
       "      <td>1.091300</td>\n",
       "      <td>0.345103</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>False</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       age  trestbps      chol    thalch   oldpeak        ca  num  \\\n",
       "0  1.0  0.912088  0.719280  0.185953  0.247221  1.151950 -0.802174  0.0   \n",
       "1  2.0  1.355613  1.558087  0.730148 -1.364202  0.434753  2.773361  2.0   \n",
       "2  3.0  1.355613 -0.678732  0.144881 -0.558491  1.420899  1.581516  1.0   \n",
       "3  4.0 -1.970826 -0.119527  0.360506  1.666808  2.227746 -0.802174  0.0   \n",
       "4  5.0 -1.527300 -0.119527 -0.111815  1.091300  0.345103 -0.802174  0.0   \n",
       "\n",
       "      sex    dataset               cp    fbs         restecg  exang  \\\n",
       "0    Male  Cleveland   typical angina   True  lv hypertrophy  False   \n",
       "1    Male  Cleveland     asymptomatic  False  lv hypertrophy   True   \n",
       "2    Male  Cleveland     asymptomatic  False  lv hypertrophy   True   \n",
       "3    Male  Cleveland      non-anginal  False          normal  False   \n",
       "4  Female  Cleveland  atypical angina  False  lv hypertrophy  False   \n",
       "\n",
       "         slope               thal  \n",
       "0  downsloping       fixed defect  \n",
       "1         flat             normal  \n",
       "2         flat  reversable defect  \n",
       "3  downsloping             normal  \n",
       "4    upsloping             normal  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalising\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data_1[numerical_features]=scaler.fit_transform(data_1[numerical_features])\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, 0 to 903\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        372 non-null    float64\n",
      " 1   age       372 non-null    float64\n",
      " 2   trestbps  372 non-null    float64\n",
      " 3   chol      372 non-null    float64\n",
      " 4   thalch    372 non-null    float64\n",
      " 5   oldpeak   372 non-null    float64\n",
      " 6   ca        372 non-null    float64\n",
      " 7   num       372 non-null    float64\n",
      " 8   sex       372 non-null    object \n",
      " 9   dataset   372 non-null    object \n",
      " 10  cp        372 non-null    object \n",
      " 11  fbs       372 non-null    object \n",
      " 12  restecg   372 non-null    object \n",
      " 13  exang     372 non-null    object \n",
      " 14  slope     372 non-null    object \n",
      " 15  thal      372 non-null    object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Cleveland        301\n",
       "Switzerland       43\n",
       "VA Long Beach     18\n",
       "Hungary           10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['dataset'].value_counts()  #to see the categories in the car=tegorical_features\n",
    "# 'sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['sex', 'fbs', 'exang', 'dataset'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m hot_categorical_features\u001b[38;5;241m=\u001b[39mbinary_cat\u001b[38;5;241m+\u001b[39mnominal_cat\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# selecting these from the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m hot_data\u001b[38;5;241m=\u001b[39mdata_1[hot_categorical_features]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      8\u001b[0m hot_encoder\u001b[38;5;241m=\u001b[39mOneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['sex', 'fbs', 'exang', 'dataset'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "binary_cat=['sex','fbs','exang']\n",
    "nominal_cat=['dataset']\n",
    "hot_categorical_features=binary_cat+nominal_cat\n",
    "# selecting these from the data\n",
    "hot_data=data_1[hot_categorical_features]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot_encoder=OneHotEncoder(sparse_output=False,drop='first')\n",
    "encoded_hot_data=hot_encoder.fit_transform(hot_data)\n",
    "encoded_hot_columns=hot_encoder.get_feature_names_out(hot_categorical_features)\n",
    "encoded_hot_df=pd.DataFrame(encoded_hot_data,columns=encoded_hot_columns)\n",
    "\n",
    "\n",
    "\n",
    "data_1.drop(hot_categorical_features, axis=1, inplace=True)  # Drop original categorical columns\n",
    "\n",
    "# data_1 = pd.concat([data_1, encoded_hot_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ordinal_cat=['cp','restecg','slope','thal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_2116\\1954193299.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  duplicated_rows = data_1[encoded_hot_df.duplicated()]\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m duplicated_rows \u001b[38;5;241m=\u001b[39m data_1[encoded_hot_df\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(duplicated_rows)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3752\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3750\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3755\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3756\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3800\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3801\u001b[0m     )\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[1;32m-> 3805\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   3807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2506\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2504\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[1;32m-> 2506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2510\u001b[0m     )\n\u001b[0;32m   2512\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   2514\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "duplicated_rows = data_1[encoded_hot_df.duplicated()]\n",
    "print(duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, 0 to 903\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        372 non-null    float64\n",
      " 1   age       372 non-null    float64\n",
      " 2   trestbps  372 non-null    float64\n",
      " 3   chol      372 non-null    float64\n",
      " 4   thalch    372 non-null    float64\n",
      " 5   oldpeak   372 non-null    float64\n",
      " 6   ca        372 non-null    float64\n",
      " 7   num       372 non-null    float64\n",
      " 8   sex       372 non-null    object \n",
      " 9   dataset   372 non-null    object \n",
      " 10  cp        372 non-null    object \n",
      " 11  fbs       372 non-null    object \n",
      " 12  restecg   372 non-null    object \n",
      " 13  exang     372 non-null    object \n",
      " 14  slope     372 non-null    object \n",
      " 15  thal      372 non-null    object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 442 entries, 0 to 371\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     372 non-null    float64\n",
      " 1   age                    372 non-null    float64\n",
      " 2   trestbps               372 non-null    float64\n",
      " 3   chol                   372 non-null    float64\n",
      " 4   thalch                 372 non-null    float64\n",
      " 5   oldpeak                372 non-null    float64\n",
      " 6   ca                     372 non-null    float64\n",
      " 7   num                    372 non-null    float64\n",
      " 8   cp                     372 non-null    object \n",
      " 9   restecg                372 non-null    object \n",
      " 10  slope                  372 non-null    object \n",
      " 11  thal                   372 non-null    object \n",
      " 12  sex_Male               372 non-null    float64\n",
      " 13  fbs_True               372 non-null    float64\n",
      " 14  exang_True             372 non-null    float64\n",
      " 15  dataset_Hungary        372 non-null    float64\n",
      " 16  dataset_Switzerland    372 non-null    float64\n",
      " 17  dataset_VA Long Beach  372 non-null    float64\n",
      "dtypes: float64(14), object(4)\n",
      "memory usage: 65.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  age  trestbps  chol  thalch  oldpeak  ca  num   cp restecg slope  \\\n",
      "304 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "305 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "307 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "308 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "310 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "313 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "314 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "315 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "316 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "317 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "318 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "319 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "322 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "323 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "324 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "325 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "326 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "327 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "328 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "329 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "330 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "332 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "333 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "334 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "335 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "336 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "337 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "338 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "339 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "340 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "341 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "343 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "344 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "346 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "347 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "348 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "349 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "350 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "351 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "352 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "353 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "356 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "357 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "358 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "359 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "360 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "361 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "362 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "364 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "365 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "367 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "369 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "370 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "371 NaN  NaN       NaN   NaN     NaN      NaN NaN  NaN  NaN     NaN   NaN   \n",
      "\n",
      "    thal  sex_Male  fbs_True  exang_True  dataset_Hungary  \\\n",
      "304  NaN       1.0       0.0         1.0              1.0   \n",
      "305  NaN       1.0       0.0         1.0              1.0   \n",
      "307  NaN       1.0       0.0         1.0              1.0   \n",
      "308  NaN       1.0       0.0         1.0              1.0   \n",
      "310  NaN       0.0       0.0         1.0              1.0   \n",
      "313  NaN       1.0       0.0         1.0              0.0   \n",
      "314  NaN       1.0       0.0         1.0              0.0   \n",
      "315  NaN       1.0       0.0         1.0              0.0   \n",
      "316  NaN       1.0       0.0         1.0              0.0   \n",
      "317  NaN       1.0       0.0         1.0              0.0   \n",
      "318  NaN       1.0       0.0         1.0              0.0   \n",
      "319  NaN       1.0       0.0         1.0              0.0   \n",
      "322  NaN       1.0       0.0         0.0              0.0   \n",
      "323  NaN       1.0       0.0         0.0              0.0   \n",
      "324  NaN       1.0       0.0         1.0              0.0   \n",
      "325  NaN       1.0       0.0         0.0              0.0   \n",
      "326  NaN       1.0       0.0         0.0              0.0   \n",
      "327  NaN       1.0       0.0         0.0              0.0   \n",
      "328  NaN       1.0       0.0         0.0              0.0   \n",
      "329  NaN       1.0       0.0         0.0              0.0   \n",
      "330  NaN       1.0       0.0         1.0              0.0   \n",
      "332  NaN       1.0       0.0         1.0              0.0   \n",
      "333  NaN       1.0       0.0         1.0              0.0   \n",
      "334  NaN       1.0       0.0         0.0              0.0   \n",
      "335  NaN       1.0       0.0         1.0              0.0   \n",
      "336  NaN       1.0       0.0         1.0              0.0   \n",
      "337  NaN       1.0       0.0         1.0              0.0   \n",
      "338  NaN       1.0       0.0         1.0              0.0   \n",
      "339  NaN       1.0       0.0         0.0              0.0   \n",
      "340  NaN       1.0       0.0         1.0              0.0   \n",
      "341  NaN       1.0       0.0         1.0              0.0   \n",
      "343  NaN       1.0       0.0         1.0              0.0   \n",
      "344  NaN       1.0       0.0         1.0              0.0   \n",
      "346  NaN       1.0       0.0         1.0              0.0   \n",
      "347  NaN       1.0       0.0         1.0              0.0   \n",
      "348  NaN       1.0       0.0         0.0              0.0   \n",
      "349  NaN       1.0       0.0         1.0              0.0   \n",
      "350  NaN       1.0       0.0         0.0              0.0   \n",
      "351  NaN       1.0       0.0         1.0              0.0   \n",
      "352  NaN       1.0       1.0         1.0              0.0   \n",
      "353  NaN       0.0       0.0         0.0              0.0   \n",
      "356  NaN       1.0       0.0         1.0              0.0   \n",
      "357  NaN       1.0       0.0         1.0              0.0   \n",
      "358  NaN       1.0       1.0         0.0              0.0   \n",
      "359  NaN       1.0       0.0         1.0              0.0   \n",
      "360  NaN       1.0       0.0         1.0              0.0   \n",
      "361  NaN       1.0       0.0         1.0              0.0   \n",
      "362  NaN       1.0       0.0         1.0              0.0   \n",
      "364  NaN       1.0       0.0         1.0              0.0   \n",
      "365  NaN       1.0       0.0         1.0              0.0   \n",
      "367  NaN       1.0       0.0         1.0              0.0   \n",
      "369  NaN       1.0       0.0         1.0              0.0   \n",
      "370  NaN       1.0       0.0         1.0              0.0   \n",
      "371  NaN       1.0       1.0         0.0              0.0   \n",
      "\n",
      "     dataset_Switzerland  dataset_VA Long Beach  \n",
      "304                  0.0                    0.0  \n",
      "305                  0.0                    0.0  \n",
      "307                  0.0                    0.0  \n",
      "308                  0.0                    0.0  \n",
      "310                  0.0                    0.0  \n",
      "313                  1.0                    0.0  \n",
      "314                  1.0                    0.0  \n",
      "315                  1.0                    0.0  \n",
      "316                  1.0                    0.0  \n",
      "317                  1.0                    0.0  \n",
      "318                  1.0                    0.0  \n",
      "319                  1.0                    0.0  \n",
      "322                  1.0                    0.0  \n",
      "323                  1.0                    0.0  \n",
      "324                  1.0                    0.0  \n",
      "325                  1.0                    0.0  \n",
      "326                  1.0                    0.0  \n",
      "327                  1.0                    0.0  \n",
      "328                  1.0                    0.0  \n",
      "329                  1.0                    0.0  \n",
      "330                  1.0                    0.0  \n",
      "332                  1.0                    0.0  \n",
      "333                  1.0                    0.0  \n",
      "334                  1.0                    0.0  \n",
      "335                  1.0                    0.0  \n",
      "336                  1.0                    0.0  \n",
      "337                  1.0                    0.0  \n",
      "338                  1.0                    0.0  \n",
      "339                  1.0                    0.0  \n",
      "340                  1.0                    0.0  \n",
      "341                  1.0                    0.0  \n",
      "343                  1.0                    0.0  \n",
      "344                  1.0                    0.0  \n",
      "346                  1.0                    0.0  \n",
      "347                  1.0                    0.0  \n",
      "348                  1.0                    0.0  \n",
      "349                  1.0                    0.0  \n",
      "350                  1.0                    0.0  \n",
      "351                  1.0                    0.0  \n",
      "352                  1.0                    0.0  \n",
      "353                  1.0                    0.0  \n",
      "356                  0.0                    1.0  \n",
      "357                  0.0                    1.0  \n",
      "358                  0.0                    1.0  \n",
      "359                  0.0                    1.0  \n",
      "360                  0.0                    1.0  \n",
      "361                  0.0                    1.0  \n",
      "362                  0.0                    1.0  \n",
      "364                  0.0                    1.0  \n",
      "365                  0.0                    1.0  \n",
      "367                  0.0                    1.0  \n",
      "369                  0.0                    1.0  \n",
      "370                  0.0                    1.0  \n",
      "371                  0.0                    1.0  \n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = data_1[data_1.duplicated()]\n",
    "print(duplicated_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'data_1' is your DataFrame containing ordinal categorical features\n",
    "\n",
    "ordinal_cat = ['cp', 'restecg', 'slope', 'thal']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each ordinal categorical column\n",
    "for feature in ordinal_cat:\n",
    "    # Fit and transform the ordinal categorical feature\n",
    "    data_1[feature] = label_encoder.fit_transform(data_1[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 442 entries, 0 to 371\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     372 non-null    float64\n",
      " 1   age                    372 non-null    float64\n",
      " 2   trestbps               372 non-null    float64\n",
      " 3   chol                   372 non-null    float64\n",
      " 4   thalch                 372 non-null    float64\n",
      " 5   oldpeak                372 non-null    float64\n",
      " 6   ca                     372 non-null    float64\n",
      " 7   num                    372 non-null    float64\n",
      " 8   cp                     442 non-null    int32  \n",
      " 9   restecg                442 non-null    int32  \n",
      " 10  slope                  442 non-null    int32  \n",
      " 11  thal                   442 non-null    int32  \n",
      " 12  sex_Male               372 non-null    float64\n",
      " 13  fbs_True               372 non-null    float64\n",
      " 14  exang_True             372 non-null    float64\n",
      " 15  dataset_Hungary        372 non-null    float64\n",
      " 16  dataset_Switzerland    372 non-null    float64\n",
      " 17  dataset_VA Long Beach  372 non-null    float64\n",
      "dtypes: float64(14), int32(4)\n",
      "memory usage: 58.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num                      1.000000\n",
       "ca                       0.461479\n",
       "oldpeak                  0.399445\n",
       "thal                     0.269606\n",
       "id                       0.246472\n",
       "age                      0.227092\n",
       "sex_Male                 0.172659\n",
       "trestbps                 0.158367\n",
       "exang_True               0.100930\n",
       "restecg                  0.053343\n",
       "fbs_True                -0.000151\n",
       "dataset_Hungary         -0.028865\n",
       "dataset_Switzerland     -0.043864\n",
       "chol                    -0.239018\n",
       "slope                   -0.353333\n",
       "cp                      -0.424200\n",
       "thalch                  -0.449275\n",
       "dataset_VA Long Beach         NaN\n",
       "Name: num, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target and data_1 find the correlation\n",
    "corr_matrix=data_1.corr()\n",
    "corr_matrix[\"num\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set ratio: 0.70\n",
      "Validation set ratio: 0.20\n",
      "Test set ratio: 0.10\n"
     ]
    }
   ],
   "source": [
    "# performing splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'preprocessed_data' is your preprocessed dataset\n",
    "\n",
    "# Splitting into training (70%) and temporary data (30%)\n",
    "train_data, temp_data = train_test_split(data_1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further splitting the temporary data into validation (20%) and test (10%)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "\n",
    "# Final ratios:\n",
    "# Training: 70% | Validation: 20% | Test: 10%\n",
    "\n",
    "# to verify the ratio\n",
    "total_samples = len(data_1)\n",
    "train_samples = len(train_data)\n",
    "validation_samples = len(validation_data)\n",
    "test_samples = len(test_data)\n",
    "\n",
    "train_ratio = train_samples / total_samples\n",
    "validation_ratio = validation_samples / total_samples\n",
    "test_ratio = test_samples / total_samples\n",
    "\n",
    "print(f\"Training set ratio: {train_ratio:.2f}\")\n",
    "print(f\"Validation set ratio: {validation_ratio:.2f}\")\n",
    "print(f\"Test set ratio: {test_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 309 entries, 226 to 103\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     266 non-null    float64\n",
      " 1   age                    266 non-null    float64\n",
      " 2   trestbps               266 non-null    float64\n",
      " 3   chol                   266 non-null    float64\n",
      " 4   thalch                 266 non-null    float64\n",
      " 5   oldpeak                266 non-null    float64\n",
      " 6   ca                     266 non-null    float64\n",
      " 7   num                    266 non-null    float64\n",
      " 8   cp                     309 non-null    int32  \n",
      " 9   restecg                309 non-null    int32  \n",
      " 10  slope                  309 non-null    int32  \n",
      " 11  thal                   309 non-null    int32  \n",
      " 12  sex_Male               256 non-null    float64\n",
      " 13  fbs_True               256 non-null    float64\n",
      " 14  exang_True             256 non-null    float64\n",
      " 15  dataset_Hungary        256 non-null    float64\n",
      " 16  dataset_Switzerland    256 non-null    float64\n",
      " 17  dataset_VA Long Beach  256 non-null    float64\n",
      "dtypes: float64(14), int32(4)\n",
      "memory usage: 41.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x_test in X:\n",
    "            distances = [self.euclidean_distance(x_test, x_train) for x_train in self.X_train]\n",
    "            # Sort by distance and return indices of the first k neighbors\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            # Get the most common class label among the k neighbors\n",
    "            most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Set the number of neighbors (k)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Fit the classifier to the training data\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(train_data, train_label)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:215\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:454\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 454\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    455\u001b[0m             X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         )\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_label = train_data.iloc[:, 7]  # Assuming the target column is at index 7\n",
    "test_label=test_data.iloc[:,7]\n",
    "# Remove the target column from the DataFrame to keep only features\n",
    "train_data = train_data.drop(columns=data_1.columns[7])\n",
    "test_data=test_data.drop(columns=data_1.columns[7])\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)  # Set the number of neighbors (k)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(train_data, train_label)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(test_data)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_label, predictions)\n",
    "print(f\"Accuracy of the KNN model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
