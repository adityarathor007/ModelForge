{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('heart_disease_uci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_features\n",
      "['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "\n",
      "numerical_features\n",
      "['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is a DataFrame or a structure like that\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "if 'id' in numerical_features:\n",
    "    numerical_features.remove('id')\n",
    "    numerical_features.remove('num')\n",
    "    \n",
    "print(\"categorical_features\")\n",
    "print(categorical_features)\n",
    "print(\"\\nnumerical_features\")\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([460.5       ,  53.51086957, 132.13240418, 199.13033708,\n",
       "       137.54566474,   0.87878788,   0.6763754 ,   0.99565217])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing missing values with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer=SimpleImputer(strategy='mean')\n",
    "\n",
    "num_data=data.drop(categorical_features,axis=1)\n",
    "imputer.fit(num_data)\n",
    "imputer.statistics_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, 0 to 903\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        372 non-null    float64\n",
      " 1   age       372 non-null    float64\n",
      " 2   trestbps  372 non-null    float64\n",
      " 3   chol      372 non-null    float64\n",
      " 4   thalch    372 non-null    float64\n",
      " 5   oldpeak   372 non-null    float64\n",
      " 6   ca        372 non-null    float64\n",
      " 7   num       372 non-null    float64\n",
      " 8   sex       372 non-null    object \n",
      " 9   dataset   372 non-null    object \n",
      " 10  cp        372 non-null    object \n",
      " 11  fbs       372 non-null    object \n",
      " 12  restecg   372 non-null    object \n",
      " 13  exang     372 non-null    object \n",
      " 14  slope     372 non-null    object \n",
      " 15  thal      372 non-null    object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# handling the missing values\n",
    "data_imputed=imputer.transform(num_data)\n",
    "\n",
    "imputed_df=pd.DataFrame(data_imputed,columns=num_data.columns)\n",
    "data_1=pd.concat([imputed_df,data[categorical_features]],axis=1)\n",
    "\n",
    "data_1.dropna(subset=categorical_features,inplace=True)  #inplace is used to ensure that new dataset is not created it just alter the original dataset\n",
    "data_1.info()\n",
    "\n",
    "# to check if rows are removed when categories value(s) are missing\n",
    "# missing_categorical = data[categorical_features].isnull().sum()\n",
    "\n",
    "# # Print or view the count of missing values in categorical columns\n",
    "# print(missing_categorical)\n",
    "\n",
    "\n",
    "# target = data_1.iloc[:, 7]  # Assuming the target column is at index 7\n",
    "\n",
    "# # Remove the target column from the DataFrame to keep only features\n",
    "# data_1 = data_1.drop(columns=data_1.columns[7])\n",
    "\n",
    "\n",
    "# to ensure that the target and data have the same number of rows as some rows where removed in because of category\n",
    "# len(data_1)\n",
    "# len(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>exang</th>\n",
       "      <th>slope</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.719280</td>\n",
       "      <td>0.185953</td>\n",
       "      <td>0.247221</td>\n",
       "      <td>1.151950</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>False</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>fixed defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.355613</td>\n",
       "      <td>1.558087</td>\n",
       "      <td>0.730148</td>\n",
       "      <td>-1.364202</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>2.773361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>True</td>\n",
       "      <td>flat</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.355613</td>\n",
       "      <td>-0.678732</td>\n",
       "      <td>0.144881</td>\n",
       "      <td>-0.558491</td>\n",
       "      <td>1.420899</td>\n",
       "      <td>1.581516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>True</td>\n",
       "      <td>flat</td>\n",
       "      <td>reversable defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.970826</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>0.360506</td>\n",
       "      <td>1.666808</td>\n",
       "      <td>2.227746</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.527300</td>\n",
       "      <td>-0.119527</td>\n",
       "      <td>-0.111815</td>\n",
       "      <td>1.091300</td>\n",
       "      <td>0.345103</td>\n",
       "      <td>-0.802174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>False</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       age  trestbps      chol    thalch   oldpeak        ca  num  \\\n",
       "0  1.0  0.912088  0.719280  0.185953  0.247221  1.151950 -0.802174  0.0   \n",
       "1  2.0  1.355613  1.558087  0.730148 -1.364202  0.434753  2.773361  2.0   \n",
       "2  3.0  1.355613 -0.678732  0.144881 -0.558491  1.420899  1.581516  1.0   \n",
       "3  4.0 -1.970826 -0.119527  0.360506  1.666808  2.227746 -0.802174  0.0   \n",
       "4  5.0 -1.527300 -0.119527 -0.111815  1.091300  0.345103 -0.802174  0.0   \n",
       "\n",
       "      sex    dataset               cp    fbs         restecg  exang  \\\n",
       "0    Male  Cleveland   typical angina   True  lv hypertrophy  False   \n",
       "1    Male  Cleveland     asymptomatic  False  lv hypertrophy   True   \n",
       "2    Male  Cleveland     asymptomatic  False  lv hypertrophy   True   \n",
       "3    Male  Cleveland      non-anginal  False          normal  False   \n",
       "4  Female  Cleveland  atypical angina  False  lv hypertrophy  False   \n",
       "\n",
       "         slope               thal  \n",
       "0  downsloping       fixed defect  \n",
       "1         flat             normal  \n",
       "2         flat  reversable defect  \n",
       "3  downsloping             normal  \n",
       "4    upsloping             normal  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalising\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data_1[numerical_features]=scaler.fit_transform(data_1[numerical_features])\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 372 entries, 0 to 903\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        372 non-null    float64\n",
      " 1   age       372 non-null    float64\n",
      " 2   trestbps  372 non-null    float64\n",
      " 3   chol      372 non-null    float64\n",
      " 4   thalch    372 non-null    float64\n",
      " 5   oldpeak   372 non-null    float64\n",
      " 6   ca        372 non-null    float64\n",
      " 7   num       372 non-null    float64\n",
      " 8   sex       372 non-null    object \n",
      " 9   dataset   372 non-null    object \n",
      " 10  cp        372 non-null    object \n",
      " 11  fbs       372 non-null    object \n",
      " 12  restecg   372 non-null    object \n",
      " 13  exang     372 non-null    object \n",
      " 14  slope     372 non-null    object \n",
      " 15  thal      372 non-null    object \n",
      "dtypes: float64(8), object(8)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Cleveland        301\n",
       "Switzerland       43\n",
       "VA Long Beach     18\n",
       "Hungary           10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['dataset'].value_counts()  #to see the categories in the car=tegorical_features\n",
    "# 'sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat=['sex','fbs','exang']\n",
    "nominal_cat=['dataset']\n",
    "hot_categorical_features=binary_cat+nominal_cat\n",
    "# selecting these from the data\n",
    "hot_data=data_1[hot_categorical_features]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot_encoder=OneHotEncoder(sparse_output=False,drop='first')\n",
    "encoded_hot_data=hot_encoder.fit_transform(hot_data)\n",
    "encoded_hot_columns=hot_encoder.get_feature_names_out(hot_categorical_features)\n",
    "encoded_hot_df=pd.DataFrame(encoded_hot_data,columns=encoded_hot_columns)\n",
    "\n",
    "\n",
    "\n",
    "data_1.drop(hot_categorical_features, axis=1, inplace=True)  # Drop original categorical columns\n",
    "\n",
    "data_1 = pd.concat([data_1, encoded_hot_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ordinal_cat=['cp','restecg','slope','thal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 302 entries, 0 to 320\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     302 non-null    float64\n",
      " 1   age                    302 non-null    float64\n",
      " 2   trestbps               302 non-null    float64\n",
      " 3   chol                   302 non-null    float64\n",
      " 4   thalch                 302 non-null    float64\n",
      " 5   oldpeak                302 non-null    float64\n",
      " 6   ca                     302 non-null    float64\n",
      " 7   num                    302 non-null    float64\n",
      " 8   cp                     302 non-null    object \n",
      " 9   restecg                302 non-null    object \n",
      " 10  slope                  302 non-null    object \n",
      " 11  thal                   302 non-null    object \n",
      " 12  sex_Male               302 non-null    float64\n",
      " 13  fbs_True               302 non-null    float64\n",
      " 14  exang_True             302 non-null    float64\n",
      " 15  dataset_Hungary        302 non-null    float64\n",
      " 16  dataset_Switzerland    302 non-null    float64\n",
      " 17  dataset_VA Long Beach  302 non-null    float64\n",
      "dtypes: float64(14), object(4)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.dropna(inplace=True) \n",
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, age, trestbps, chol, thalch, oldpeak, ca, num, cp, restecg, slope, thal, sex_Male, fbs_True, exang_True, dataset_Hungary, dataset_Switzerland, dataset_VA Long Beach]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# to print duplicated rows\n",
    "duplicated_rows = data_1[data_1.duplicated()]\n",
    "print(duplicated_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'data_1' is your DataFrame containing ordinal categorical features\n",
    "\n",
    "ordinal_cat = ['cp', 'restecg', 'slope', 'thal']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each ordinal categorical column\n",
    "for feature in ordinal_cat:\n",
    "    # Fit and transform the ordinal categorical feature\n",
    "    data_1[feature] = label_encoder.fit_transform(data_1[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 302 entries, 0 to 320\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     302 non-null    float64\n",
      " 1   age                    302 non-null    float64\n",
      " 2   trestbps               302 non-null    float64\n",
      " 3   chol                   302 non-null    float64\n",
      " 4   thalch                 302 non-null    float64\n",
      " 5   oldpeak                302 non-null    float64\n",
      " 6   ca                     302 non-null    float64\n",
      " 7   num                    302 non-null    float64\n",
      " 8   cp                     302 non-null    int32  \n",
      " 9   restecg                302 non-null    int32  \n",
      " 10  slope                  302 non-null    int32  \n",
      " 11  thal                   302 non-null    int32  \n",
      " 12  sex_Male               302 non-null    float64\n",
      " 13  fbs_True               302 non-null    float64\n",
      " 14  exang_True             302 non-null    float64\n",
      " 15  dataset_Hungary        302 non-null    float64\n",
      " 16  dataset_Switzerland    302 non-null    float64\n",
      " 17  dataset_VA Long Beach  302 non-null    float64\n",
      "dtypes: float64(14), int32(4)\n",
      "memory usage: 40.1 KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num                      1.000000\n",
       "ca                       0.519151\n",
       "oldpeak                  0.503318\n",
       "thal                     0.349913\n",
       "age                      0.227127\n",
       "sex_Male                 0.172659\n",
       "trestbps                 0.160536\n",
       "exang_True               0.100930\n",
       "chol                     0.067093\n",
       "id                       0.018769\n",
       "fbs_True                -0.000151\n",
       "dataset_Hungary         -0.028865\n",
       "dataset_Switzerland     -0.043864\n",
       "restecg                 -0.141163\n",
       "slope                   -0.373063\n",
       "cp                      -0.415741\n",
       "thalch                  -0.424055\n",
       "dataset_VA Long Beach         NaN\n",
       "Name: num, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target and data_1 find the correlation\n",
    "corr_matrix=data_1.corr()\n",
    "corr_matrix[\"num\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set ratio: 0.70\n",
      "Validation set ratio: 0.20\n",
      "Test set ratio: 0.10\n"
     ]
    }
   ],
   "source": [
    "# performing splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'preprocessed_data' is your preprocessed dataset\n",
    "\n",
    "# Splitting into training (70%) and temporary data (30%)\n",
    "train_data, temp_data = train_test_split(data_1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further splitting the temporary data into validation (20%) and test (10%)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "\n",
    "# Final ratios:\n",
    "# Training: 70% | Validation: 20% | Test: 10%\n",
    "\n",
    "# to verify the ratio\n",
    "total_samples = len(data_1)\n",
    "train_samples = len(train_data)\n",
    "validation_samples = len(validation_data)\n",
    "test_samples = len(test_data)\n",
    "\n",
    "train_ratio = train_samples / total_samples\n",
    "validation_ratio = validation_samples / total_samples\n",
    "test_ratio = test_samples / total_samples\n",
    "\n",
    "print(f\"Training set ratio: {train_ratio:.2f}\")\n",
    "print(f\"Validation set ratio: {validation_ratio:.2f}\")\n",
    "print(f\"Test set ratio: {test_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211 entries, 125 to 103\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     211 non-null    float64\n",
      " 1   age                    211 non-null    float64\n",
      " 2   trestbps               211 non-null    float64\n",
      " 3   chol                   211 non-null    float64\n",
      " 4   thalch                 211 non-null    float64\n",
      " 5   oldpeak                211 non-null    float64\n",
      " 6   ca                     211 non-null    float64\n",
      " 7   num                    211 non-null    float64\n",
      " 8   cp                     211 non-null    int32  \n",
      " 9   restecg                211 non-null    int32  \n",
      " 10  slope                  211 non-null    int32  \n",
      " 11  thal                   211 non-null    int32  \n",
      " 12  sex_Male               211 non-null    float64\n",
      " 13  fbs_True               211 non-null    float64\n",
      " 14  exang_True             211 non-null    float64\n",
      " 15  dataset_Hungary        211 non-null    float64\n",
      " 16  dataset_Switzerland    211 non-null    float64\n",
      " 17  dataset_VA Long Beach  211 non-null    float64\n",
      "dtypes: float64(14), int32(4)\n",
      "memory usage: 28.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X.values  # Convert DataFrame to NumPy array\n",
    "        self.y_train = y.values  # Convert DataFrame to NumPy array\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_data = X.values  # Convert DataFrame to NumPy array\n",
    "        predictions = [self._predict(x) for x in X_data]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['num'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_label\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Remove the target column from the DataFrame to keep only features\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m test_data\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mdata_1\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m7\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['num'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_label = train_data.iloc[:, 7]  # Assuming the target column is at index 7\n",
    "test_label=test_data.iloc[:,7]\n",
    "# Remove the target column from the DataFrame to keep only features\n",
    "train_data = train_data.drop(columns=data_1.columns[7])\n",
    "test_data=test_data.drop(columns=data_1.columns[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['num'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m validation_label \u001b[38;5;241m=\u001b[39m validation_data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m7\u001b[39m]  \u001b[38;5;66;03m# Assuming the target column is at index 7\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Remove the target column from the DataFrame to keep only features\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m validation_data\u001b[38;5;241m=\u001b[39m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['num'] not found in axis\""
     ]
    }
   ],
   "source": [
    "validation_label = validation_data.iloc[:, 7]  # Assuming the target column is at index 7\n",
    "\n",
    "# Remove the target column from the DataFrame to keep only features\n",
    "validation_data=validation_data.drop(columns=data_1.columns[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31 entries, 93 to 33\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     31 non-null     float64\n",
      " 1   age                    31 non-null     float64\n",
      " 2   trestbps               31 non-null     float64\n",
      " 3   chol                   31 non-null     float64\n",
      " 4   thalch                 31 non-null     float64\n",
      " 5   oldpeak                31 non-null     float64\n",
      " 6   ca                     31 non-null     float64\n",
      " 7   cp                     31 non-null     int32  \n",
      " 8   restecg                31 non-null     int32  \n",
      " 9   slope                  31 non-null     int32  \n",
      " 10  thal                   31 non-null     int32  \n",
      " 11  sex_Male               31 non-null     float64\n",
      " 12  fbs_True               31 non-null     float64\n",
      " 13  exang_True             31 non-null     float64\n",
      " 14  dataset_Hungary        31 non-null     float64\n",
      " 15  dataset_Switzerland    31 non-null     float64\n",
      " 16  dataset_VA Long Beach  31 non-null     float64\n",
      "dtypes: float64(13), int32(4)\n",
      "memory usage: 4.9 KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 64.52%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your training data X_train and corresponding labels y_train\n",
    "\n",
    "# Instantiate your KNN model\n",
    "knn = KNN(k=11)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have fitted the model with your training data\n",
    "knn.fit(train_data,train_label)\n",
    "\n",
    "# # Predict labels using the trained model on the training data itself\n",
    "train_predictions = knn.predict(test_data)\n",
    "\n",
    "# # Calculate accuracy\n",
    "correct_predictions = sum(predicted == actual for predicted, actual in zip(train_predictions, test_label))\n",
    "accuracy = correct_predictions / len(test_label) * 100\n",
    "\n",
    "print(f\"Accuracy on training data: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the KNN model: 0.65\n"
     ]
    }
   ],
   "source": [
    "# using scikit learn library\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)  # Set the number of neighbors (k)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(train_data, train_label)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(test_data)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_label, predictions)\n",
    "print(f\"Accuracy of the KNN model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Accuracy on training data: 74.19%\n",
      "Fold 2:\n",
      "Accuracy on training data: 70.97%\n",
      "Fold 3:\n",
      "Accuracy on training data: 80.65%\n",
      "Fold 4:\n",
      "Accuracy on training data: 90.32%\n",
      "Fold 5:\n",
      "Accuracy on training data: 64.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have your data: X (features) and y (labels)\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_data, train_label)):\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    X_train, y_train = train_data.iloc[train_idx], train_label.iloc[train_idx]\n",
    "    X_val, y_val = train_data.iloc[val_idx], train_label.iloc[val_idx]\n",
    "\n",
    "    # Apply bootstrapping to create a diverse training set within each fold\n",
    "    n_samples = len(train_idx)\n",
    "    bootstrap_indices = np.random.choice(train_idx, size=n_samples, replace=True)\n",
    "    X_train_bootstrap, y_train_bootstrap = train_data.iloc[bootstrap_indices], train_label.iloc[bootstrap_indices]\n",
    "    \n",
    "    # Train your model here using X_train_bootstrap, y_train_bootstrap\n",
    "    # Evaluate your model using X_val, y_val\n",
    "    \n",
    "\n",
    "    knn = KNN(k=3)\n",
    "\n",
    "\n",
    "\n",
    "    # Assuming you have fitted the model with your training data\n",
    "    knn.fit(X_train_bootstrap,y_train_bootstrap)\n",
    "\n",
    "    # # Predict labels using the trained model on the training data itself\n",
    "    train_predictions = knn.predict(validation_data)\n",
    "\n",
    "    # # Calculate accuracy\n",
    "    correct_predictions = sum(predicted == actual for predicted, actual in zip(train_predictions, validation_label))\n",
    "    accuracy = correct_predictions / len(test_label) * 100\n",
    "\n",
    "    print(f\"Accuracy on training data: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Accuracy for Fold 1: 0.36666666666666664\n",
      "Fold 2:\n",
      "Accuracy for Fold 2: 0.48333333333333334\n",
      "Fold 3:\n",
      "Accuracy for Fold 3: 0.3\n",
      "Fold 4:\n",
      "Accuracy for Fold 4: 0.4\n",
      "Fold 5:\n",
      "Accuracy for Fold 5: 0.4166666666666667\n",
      "\n",
      "Average Accuracy: 0.3933333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have your data: X (features) and y (labels)\n",
    "\n",
    "# Initialize StratifiedKFold with 5 folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracies = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_data, train_label)):\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    X_train, y_train = train_data.iloc[train_idx], train_label.iloc[train_idx]\n",
    "    X_val, y_val = train_data.iloc[val_idx], train_label.iloc[val_idx]\n",
    "\n",
    "    # Apply bootstrapping to create a diverse training set within each fold\n",
    "    n_samples = len(train_idx)\n",
    "    bootstrap_indices = np.random.choice(train_idx, size=n_samples, replace=True)\n",
    "    X_train_bootstrap, y_train_bootstrap = train_data.iloc[bootstrap_indices], train_label.iloc[bootstrap_indices]\n",
    "\n",
    "    # Initialize and train K-Nearest Neighbors classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = knn.predict(validation_data)\n",
    "    accuracy = accuracy_score(validation_label, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Accuracy for Fold {fold + 1}: {accuracy}\")\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "print(f\"\\nAverage Accuracy: {avg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
